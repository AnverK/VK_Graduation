{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, GridSearchCV, KFold\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "from src.utils import *\n",
    "from src.MetricLinearRegression import MetricLinearRegression\n",
    "from src.InstrumentalVariable import InstrumentalVariable\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def grid_search(X, y):\n",
    "    iv_model = InstrumentalVariable()\n",
    "    grid_nu = np.linspace(0.0001, 0.2, num=20)\n",
    "    grid_reg = np.logspace(-5, 5, num=20)\n",
    "    grid_p_value = np.linspace(0, 98, num=20)\n",
    "    params = {'l2_reg': grid_reg, 'critical_p_value': grid_p_value, 'nu': grid_nu}\n",
    "    gs = GridSearchCV(iv_model, param_grid=params, scoring=make_scorer(r2_score), cv=10, verbose=1, n_jobs=-1)\n",
    "    gs.fit(X, y)\n",
    "    return gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_regression_model(model, X, y):\n",
    "    scores = cross_validate(model, X, y, scoring=make_scorer(r2_score), cv=10, n_jobs=-1)\n",
    "    return np.mean(scores['test_score'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_model_with_outliers(model, X, y, nu=0.1, n_splits=5, bootstrap=True, score=r2_score):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    metric = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        outliers = get_outlier_experiments(np.append(X_train[:,:,0], np.reshape(y_train, (-1, 1)), axis=1), nu=nu)\n",
    "        mask = np.ones(len(X_train), np.bool)\n",
    "        mask[outliers] = 0\n",
    "        X_train, y_train = X_train[mask], y_train[mask]\n",
    "        if bootstrap:\n",
    "            bootstrap_inds = np.random.choice(len(X_train), len(X_train))\n",
    "            X_train, y_train = X_train[bootstrap_inds], y_train[bootstrap_inds]\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        metric += score(y_test, y_pred)\n",
    "    return metric / n_splits\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def draw_long_short_plots(short_metrics, long_metrics, outliers=None, l0reg = None):\n",
    "    for i, short in enumerate(short_metrics.swapaxes(0, 1)):\n",
    "        inds = None\n",
    "        if l0reg is not None:\n",
    "            inds = extract_painted_inds(short, l0reg)\n",
    "            short = short[inds]\n",
    "        for j, long in enumerate(long_metrics.swapaxes(0, 1)):\n",
    "            if inds is not None:\n",
    "                long = long[inds]\n",
    "            plt.plot(short[:, 0], long[:, 0], 'b.')\n",
    "            if outliers is not None:\n",
    "                outlined_short = short[outliers]\n",
    "                outlined_long = long[outliers]\n",
    "                plt.plot(outlined_short[:, 0], outlined_long[:, 0], 'r.')            \n",
    "            if l0reg is None:\n",
    "                plt.title('Long term metric dependency on short term metrics without l0 regularization')\n",
    "            else:\n",
    "                plt.title('Long term metric dependency on short term metrics with l0 regularization: ' + str(l0reg))\n",
    "            plt.xlabel('short metric: ' + str(i))\n",
    "            plt.ylabel('long metric: ' + str(j))\n",
    "            plt.show()    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "short_metrics_p, long_metrics_p = read_data(shift=True)\n",
    "short_metrics = short_metrics_p[:, :, 0]\n",
    "long_metrics = long_metrics_p[:, :, 0]\n",
    "\n",
    "target_metric_p = long_metrics_p[:, 3, :]   # <--- here you can choose target (0, 1, 2, 3)\n",
    "target_metric = target_metric_p[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "r2 = []\n",
    "nu_l = np.linspace(0.0001, 0.3, num=100)\n",
    "for nu in nu_l:\n",
    "    iv_model = InstrumentalVariable(90)\n",
    "    cur_r2 = evaluate_model_with_outliers(iv_model, short_metrics_p, target_metric, nu=nu, n_splits=10)\n",
    "    if cur_r2 < 0:  #<-- it is for better visualisation, for target_metric_0 it should be changed on -1\n",
    "        cur_r2 = 0\n",
    "    r2.append(cur_r2)\n",
    "plt.plot(nu_l, r2, 'b.')\n",
    "plt.xlabel('nu')\n",
    "plt.ylabel('r2')\n",
    "# plt.savefig('MSE_nu_dependency.pdf')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r2 = []\n",
    "l2_reg_l = np.linspace(0, 10, num=100)\n",
    "for l2_reg in l2_reg_l:\n",
    "    iv_model = InstrumentalVariable(90, l2_reg)\n",
    "    cur_r2 = evaluate_model_with_outliers(iv_model, short_metrics_p, target_metric, nu=0.1, n_splits=10)\n",
    "    if cur_r2 < -1:\n",
    "        cur_r2 = -1\n",
    "    r2.append(cur_r2)\n",
    "plt.plot(l2_reg_l, r2, 'b.')\n",
    "plt.xlabel('l2_reg')\n",
    "plt.ylabel('r2')\n",
    "# plt.savefig('MSE_l2_dependency.pdf')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "outliers = get_outlier_experiments(np.append(short_metrics, long_metrics, axis=1))\n",
    "draw_long_short_plots(short_metrics_p, long_metrics_p, outliers=outliers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}